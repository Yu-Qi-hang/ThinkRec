{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结item的关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelscope import AutoModelForCausalLM, AutoTokenizer\n",
    "from modelscope import GenerationConfig\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置GPU\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model to directory: /home/yuqihang/.cache/modelscope/hub/models/damo/nlp_polylm_qwen_7b_text_generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-24 11:37:46,577 - modelscope - INFO - Use user-specified model revision: v1.0.1\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"damo/nlp_polylm_qwen_7b_text_generation\", revision = 'v1.0.1', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"/data/yuqihang/model/DeepSeek-R1-Distill-Qwen-1.5B\").eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'qwen2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/data/yuqihang/model/DeepSeek-R1-Distill-Qwen-1.5B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbf16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39meval()\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/data/yuqihang/envs/envs/llara/lib/python3.10/site-packages/modelscope/utils/hf_util/patcher.py:225\u001b[0m, in \u001b[0;36m_patch_pretrained_class.<locals>.get_wrapped_class.<locals>.ClassWrapper.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pretrained_model_name_or_path,\n\u001b[1;32m    218\u001b[0m                     \u001b[38;5;241m*\u001b[39mmodel_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    219\u001b[0m     model_dir \u001b[38;5;241m=\u001b[39m get_model_dir(\n\u001b[1;32m    220\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m    221\u001b[0m         ignore_file_pattern\u001b[38;5;241m=\u001b[39mignore_file_pattern,\n\u001b[1;32m    222\u001b[0m         allow_file_pattern\u001b[38;5;241m=\u001b[39mallow_file_pattern,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 225\u001b[0m     module_obj \u001b[38;5;241m=\u001b[39m \u001b[43mmodule_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module_class\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoModel\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    229\u001b[0m         module_obj\u001b[38;5;241m.\u001b[39mmodel_dir \u001b[38;5;241m=\u001b[39m model_dir\n",
      "File \u001b[0;32m/data/yuqihang/envs/envs/llara/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:441\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs_copy\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    439\u001b[0m         _ \u001b[38;5;241m=\u001b[39m kwargs_copy\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 441\u001b[0m     config, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_unused_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs_copy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mauto_map:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m trust_remote_code:\n",
      "File \u001b[0;32m/data/yuqihang/envs/envs/llara/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:937\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[0;32m--> 937\u001b[0m     config_class \u001b[38;5;241m=\u001b[39m \u001b[43mCONFIG_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config_class\u001b[38;5;241m.\u001b[39mfrom_dict(config_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwargs)\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    940\u001b[0m     \u001b[38;5;66;03m# Fallback: use pattern matching on the string.\u001b[39;00m\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;66;03m# We go from longer names to shorter names to catch roberta before bert (for instance)\u001b[39;00m\n",
      "File \u001b[0;32m/data/yuqihang/envs/envs/llara/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:643\u001b[0m, in \u001b[0;36m_LazyConfigMapping.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extra_content[key]\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mapping:\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    644\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mapping[key]\n\u001b[1;32m    645\u001b[0m module_name \u001b[38;5;241m=\u001b[39m model_type_to_module_name(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'qwen2'"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"/home/yuqihang/.cache/modelscope/hub/models/damo/nlp_polylm_qwen_7b_text_generation\", revision = 'v1.0.1',trust_remote_code=True, bf16=True).eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model to directory: /home/yuqihang/.cache/modelscope/hub/models/damo/nlp_polylm_qwen_7b_text_generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-24 12:52:11,985 - modelscope - INFO - Use user-specified model revision: v1.0.1\n"
     ]
    }
   ],
   "source": [
    "# 创建 GenerationConfig 对象\n",
    "generation_config = GenerationConfig.from_pretrained(\n",
    "    \"damo/nlp_polylm_qwen_7b_text_generation\",\n",
    "    revision='v1.0.1',\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# 更新配置参数\n",
    "generation_config.max_new_tokens = 32\n",
    "generation_config.min_length = 1\n",
    "generation_config.do_sample = False  # 禁用采样，启用贪婪搜索\n",
    "generation_config.num_beams = 4      # 使用束搜索，宽度为 4\n",
    "generation_config.num_return_sequences = 1  # 返回一个序列\n",
    "generation_config.repetition_penalty = 1.2  # 重复惩罚系数\n",
    "generation_config.no_repeat_ngram_size = 2  # 不重复的 n-gram 大小\n",
    "generation_config.early_stopping = True\n",
    "\n",
    "# 将配置应用到模型\n",
    "model.generation_config = generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = '/home/yuqihang/projects/CoLLM/collm-datasets/booknew/id2title.json'\n",
    "rawdict = json.load(open(json_path, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = ['book','movie']\n",
    "data_type_id = 0\n",
    "prompt_prefix = f'You are a skilled text summarizer. Your task is to extract up to ten key words from the given profile of the {data_types[data_type_id]} above. Do not include the word \"book\" in your summary. Answers should contain only keywords, which should be separated by commas.\\nKeywords:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_desc(meta:dict)->str:\n",
    "    description = ''\n",
    "    candidates = ['category','brand','price','description']\n",
    "    for item in candidates:\n",
    "        if item in meta:\n",
    "            description = f'{description}\"{item.capitalize()}\":{\" \".join(meta[item].replace(\"...\",\".\").replace(\"&\",\"and\").replace(\"Book\",\"\").replace(\"book\",\"\").split()[:100])}.'\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Description\":\"I didn't want to put it down the entire time I was reading .I still can't stop thinking about it.\" --Megan, Starky Reviews \"Great storytelling . This isNOT a cookie-cutter dystopian read.\" --Dianne, Tome Tender Book Blog \"This book was AWESOME!. An epic read . If you . love books like The Hunger Games, Divergent, and The Maze Runner, this book is right up your alley .Five stars!\" --Stephanie, TeacherofYA's Book Blog \"This book is incredible! . Imaginative . fast paced . full of action . filled with a lot of twists and turns . and the world building is.\"Brand\":Yilin Publisher.\"Price\":$87.1.\n"
     ]
    }
   ],
   "source": [
    "testdic = {\n",
    "    'description':\"\\\"I didn't want to put it down the entire time I was reading ...I still can't stop thinking about it.\\\" --Megan, Starky Reviews \\\"Great storytelling ... This isNOT a cookie-cutter dystopian read.\\\" --Dianne, Tome Tender Book Blog \\\"This book was AWESOME!... An epic read ... If you ... love books like The Hunger Games, Divergent, and The Maze Runner, this book is right up your alley ...Five stars!\\\" --Stephanie, TeacherofYA's Book Blog \\\"This book is incredible! ... Imaginative ... fast paced ... full of action ... filled with a lot of twists and turns ... and the world building is truly fantastic ... 5 Brilliant Stars.\\\" --Karen Jo, Sincerely Karen Jo \\\"5 Stars!!!!!! Unputdownable!! ... My new favorite book ... If YOU love a good dystopian + romance ... Then you need this book in your life.\\\" --Megan,i fall in love book blog \\\"An intensely awesome read ... The suspense and the thrilling scenarios kept me on edge ... Very creative and brilliant ... Highly recommended.\\\" --Denise, Goodreads \\\"This bookoffers everything from action to romance with twists that keep you guessing. If you enjoyedthe Divergent Seriesyou will definitely enjoy this! A must-read.\\\" --Ashley, Goodreads \\\"This post-apocalyptic, young adult, science fiction is a page turner from start to finish!Similar to The Giver in the beginning and things just get more and more interesting ... Highly recommend!\\\" -- Susie, Goodreads \\\"An amazing read .. Most stories seem predictable at some point but this one surprised me. At only one single point was I able to say, yep I see what's going to happen next. Yeah, right. I was totally wrong.\\\" --Amanda, Goodreads\",\n",
    "    'brand':'Yilin Publisher',\n",
    "    'price':'$87.1'\n",
    "}\n",
    "print(get_desc(testdic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Description\":\"I didn't want to put it down the entire time I was reading .I still can't stop thinking about it.\" --Megan, Starky Reviews \"Great storytelling . This isNOT a cookie-cutter dystopian read.\" --Dianne, Tome Tender Book Blog \"This book was AWESOME!. An epic read . If you . love books like The Hunger Games, Divergent, and The Maze Runner, this book is right up your alley .Five stars!\" --Stephanie, TeacherofYA's Book Blog \"This book is incredible! . Imaginative . fast paced . full of action . filled with a lot of twists and turns . and the world building is.\"Brand\":Yilin Publisher.\"Price\":$87.1.\n",
      "You are a skilled text summarizer. Your task is to extract up to ten key words from the given profile of the book above. Do not include the word \"book\" in your summary. Answers should contain only keywords, which should be separated by commas.\n",
      "Keywords: dystopia, post-apocalyptic, science fiction, survival, young adult, action, adventure, romance, love, family, friendship, betrayal, loss, death\n",
      "dystopia, post-apocalyptic, science fiction, survival, young adult, action, adventure, romance, love, family\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(f'{get_desc(testdic)}\\n{prompt_prefix}', return_tensors='pt')\n",
    "inputs = inputs.to(device)\n",
    "pred = model.generate(**inputs)\n",
    "raw = tokenizer.decode(pred.cpu()[0], skip_special_tokens=True)\n",
    "print(raw)\n",
    "keywords = ', '.join(raw.split('Keywords:')[-1].strip().replace('\"','').split(', ')[:10])\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:06<00:24,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " literature, fiction, dramas, plays\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:12<00:18,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " literature, fiction, classics, brand, visit, amazon, robert, louis, stevenson, page\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:15<00:09,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shakespeare, William, Biography, Drama, History, Literature, Poetry, Plays, Sonnets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:19<00:04,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fiction, literature, piper, watty, price, description, when, other, engines, refuses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:28<00:00,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " book, children's, classic, dr, seuss, page, price, summary, text, title\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sbar = tqdm(total=5)\n",
    "for idx,meta in list(rawdict.items())[:5]:\n",
    "    inputs = tokenizer(f'{get_desc(meta)}\\n{prompt_prefix}:', return_tensors='pt')\n",
    "    inputs = inputs.to(device)\n",
    "    pred = model.generate(**inputs)\n",
    "    raw = tokenizer.decode(pred.cpu()[0], skip_special_tokens=True)\n",
    "    raw_words = raw.split('Keywords:')[-1].strip()\n",
    "    cleaned_words = raw_words.replace('\"','').replace(':','').replace('  ',' ').split(', ')\n",
    "    filer_words = list(filter(lambda x: x not in ['book','books','Book','Books'], cleaned_words))[:10]\n",
    "    # print(raw)\n",
    "    keywords = ', '.join(filer_words)\n",
    "    # rawdict[idx]['keywords'] = keywords\n",
    "    torch.cuda.empty_cache()\n",
    "    sbar.set_postfix(keywords=keywords)\n",
    "    sbar.update()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
